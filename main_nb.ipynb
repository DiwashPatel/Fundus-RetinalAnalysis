{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd569100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from openai.types.chat import ChatCompletionUserMessageParam\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0afe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  \n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edc67ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\" Please analyze the optic disc photograph I will upload and reply with exactly the following JSON object—nothing else. Use these rules for every field:\n",
    "• If a value is not discernible, enter \"unknown\" (or an empty array [] where noted).\n",
    "• Do not add comments or extra keys.\n",
    "• Keep number formatting exactly as specified.\n",
    "\n",
    "{\n",
    "  \"vcdratio (Vertical Cup-Disc Ratio)\": \"0.0-0.9 in 0.1 increments or 'unknown'\",\n",
    "  \"hcdratio (Horizontal Cup-Disc Ratio)\": \"0.0-0.9 in 0.1 increments or 'unknown'\",\n",
    "  \"dischem (Disc Hemorrhage)\": \"'Yes'/'No'/'unknown'\",\n",
    "  \"dhemlocn (Disc Hemorrhage Location)\": \"['clock hours (e.g., \\\"7:00\\\")'] or []\",\n",
    "  \"rimnotch (Rim Notch)\": \"'Yes'/'No'/'unknown'\",\n",
    "  \"ntchclkhrs (Rim Notch Location)\": \"['clock hours (e.g., \\\"7:30\\\")'] or []\",\n",
    "  \"pericrescent (Peripapillary Atrophy Crescent)\": \"'Yes'/'No'/'unknown'\",\n",
    "  \"rimthin (Rim Thinning)\": \"'Yes'/'No'/'unknown'\",\n",
    "  \"rimthinloc (Rim Thinning Location)\": \"['clock hour location (e.g., \\\"7:00\\\")'] or []\",\n",
    "  \"clarity (Image Clarity)\": \"'Good'/'Fair'/'Poor'/'unknown'\",\n",
    "  \"glaucoma (Glaucoma Diagnosis)\": \"'Yes'/'No'/'unknown'\"\n",
    "}\n",
    "\n",
    "RULES:\n",
    "1. Use clock-hour notation (e.g., '7:30') for locations\n",
    "2. For unclear features, use 'unknown'\n",
    "3. Empty arrays [] when no locations exist\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b7e1576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processed keeps tracks of images that are successfully analysed\n",
    "processed = set() \n",
    "results = []       # Stores all results\n",
    "\n",
    "#Getting all the images\n",
    "IMAGE_FOLDER = \"images\"\n",
    "all_images = {\n",
    "    f for f in os.listdir(IMAGE_FOLDER) \n",
    "    if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6dc39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_name):\n",
    "    \"\"\"Convert image to base64 string\"\"\"\n",
    "    img_path = os.path.join(IMAGE_FOLDER, image_name)\n",
    "    with open(img_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "def analyze_image(image_name):\n",
    "    \"\"\"Analyze single image and return result\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": PROMPT},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{encode_image(image_name)}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        if not response.choices or not hasattr(response.choices[0], \"message\"):\n",
    "            print(f\"No choices/message returned for {image_name}\")\n",
    "            return None\n",
    "        \n",
    "        generated_content = response.choices[0].message.content\n",
    "\n",
    "        if not generated_content:\n",
    "            print(f\"No content returned for {image_name}\")\n",
    "            return None\n",
    "        \n",
    "        result = json.loads(generated_content)\n",
    "        result[\"image_name\"] = image_name\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_name}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91a4dc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_filename = f'results_{timestamp}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8648291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 90002-CV822-R.jpg\n",
      "Processed: 90001-KW254-R.jpg\n",
      "Processed: 90001-VR219-L.jpg\n",
      "Processed: 90001-KW254-L.jpg\n",
      "Processed: 90001-VR219-R.jpg\n",
      "Processed: 90002-CV822-L.jpg\n"
     ]
    }
   ],
   "source": [
    "# Process each image\n",
    "for img_name in all_images:\n",
    "    if img_name not in processed:\n",
    "        result = analyze_image(img_name)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            processed.add(img_name)\n",
    "            print(f\"Processed: {img_name}\")\n",
    "\n",
    "            #Saves after reach result (In case the script stops unexpectedly)\n",
    "            pd.DataFrame(results).to_csv(f\"{output_filename}.csv\", index=False)\n",
    "        time.sleep(1)  # Avoid rate limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e291132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to {output_filename}\n"
     ]
    }
   ],
   "source": [
    "# Save to Excel\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    # Move 'image_name' to the first column\n",
    "    cols = df.columns.tolist()\n",
    "    if \"image_name\" in cols:\n",
    "        cols.insert(0, cols.pop(cols.index(\"image_name\")))\n",
    "        df = df[cols]\n",
    "    df.to_excel(f\"{output_filename}.xlsx\", index=False)\n",
    "    print(\"Saved results to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_two_files(results_file, ground_truth_file = \"last_visit_with_img_exist_subcol_v2.csv\"):\n",
    "    \"\"\"\n",
    "    Merges the Results file with Ground truth file. \n",
    "    Just pass the name of the results_file. \n",
    "    For eg:\n",
    "    results.xlsx\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "\n",
    "\n",
    "    # Load files\n",
    "    ground_truth_df = pd.read_csv(ground_truth_file)     # First table (CSV)\n",
    "    results_df = pd.read_excel(results_file)            # ChatGPT results with image_name\n",
    "\n",
    "    # Extract ran_id, tracking, eye from image_name\n",
    "    results_df[['ran_id', 'tracking', 'eye']] = results_df['image_name'].str.replace('.jpg', '').str.split('-', expand=True)\n",
    "\n",
    "    # Convert ran_id to integer to match ground truth\n",
    "    results_df['ran_id'] = results_df['ran_id'].astype(int)\n",
    "\n",
    "    # Merge both files on ran_id, tracking, eye\n",
    "    merged_df = pd.merge(\n",
    "    ground_truth_df,\n",
    "    results_df,\n",
    "    how='left',\n",
    "    on=['ran_id', 'tracking', 'eye']\n",
    "    )\n",
    "\n",
    "    # Optional: Sort to keep left/right eye order consistent\n",
    "    merged_df = merged_df.sort_values(by=['ran_id', 'eye_no']).reset_index(drop=True)\n",
    "\n",
    "    # Create timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    # Save merged result with timestamp in filename\n",
    "    output_filename = f'merged_output_{timestamp}.xlsx'\n",
    "    merged_df.to_excel(output_filename, index=False)\n",
    "\n",
    "    print(f\"Merged file saved as: {output_filename}\")\n",
    "\n",
    "\n",
    "#Just change the file name and it's done\n",
    "merge_two_files(\"results_1.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fundus_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
