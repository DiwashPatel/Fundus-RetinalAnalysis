# Fundus Image Analysis with GPT-4 Vision

This repository provides a pipeline to analyze fundus (optic disc) images using OpenAI's GPT-4 Vision model. The code processes images, extracts clinical features, merges results with ground truth, and evaluates model performance with a variety of metrics and plots.

---

## ğŸ“ Folder Structure

```
.
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ Sample with available VCDR.xlsx
â”œâ”€â”€ images/
â”‚   â””â”€â”€ (your .jpg/.jpeg/.png files)
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ merged_on_ranid_tracking_<timestamp>.xlsx
â”‚   â””â”€â”€ (results_*.csv, results_*.xlsx, processed_images.txt, etc.)
â”œâ”€â”€ evaluations/
â”‚   â””â”€â”€ <timestamp>/
â”‚       â”œâ”€â”€ metrics.txt
â”‚       â”œâ”€â”€ Confusion matrix.png
â”‚       â””â”€â”€ *_scatter.png
â”œâ”€â”€ main.py
â”œâ”€â”€ main_nb.ipynb
â”œâ”€â”€ merge_files.py
â”œâ”€â”€ concat_tables.py
â”œâ”€â”€ evaluate_results.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸš€ How to Use

### 1. **Prepare Your Data**
- Place your fundus images in the `images/` folder.
- Place your ground truth dataset (e.g., `Sample with available VCDR.xlsx`) in the `datasets/` folder.

### 2. **Merge Results with Ground Truth**

- Open `concat_tables.py`.
- **Important:**  
  On line 7, ensure the `ground_truth_file` matches your dataset file name:
  ```python
  ground_truth_file=os.path.join("datasets", 'Sample with available VCDR.xlsx')
  ```
  Change the file name if your dataset is named differently.

- Run the script:
  ```sh
  python concat_tables.py
  ```
- This will generate a file in `results/` named like:
  ```
  merged_on_ranid_tracking_<date>.xlsx
  ```
  Use this merged file for evaluation.

### 3. **Evaluate Model Metrics**

- Open `evaluate_results.py`.
- **Important:**  
  On line 24, set the `file_name` variable to the latest merged file you want to evaluate:
  ```python
  file_name = "merged_on_ranid_tracking_20250624_155649.xlsx"
  ```
- Run the script:
  ```sh
  python evaluate_results.py
  ```
- This will create a new subfolder in `evaluations/` with the current timestamp.  
  Inside, you'll find:
  - `metrics.txt` (all evaluation metrics)
  - `Confusion matrix.png`
  - Scatter plots for numeric variables

---

## ğŸ“ Notes & Assumptions

- **Ground Truth Labels:**  
  In the ground truth (`fundus_label` column), there are two categories:  
  - `'normal'` (considered as normal, mapped to 0)
  - `'poag'` (considered as not normal, mapped to 1)

- **Prediction Labels:**  
  In the predictions (`glaucoma` column), values are `'Yes'` (1) and `'No'` (0).

- **Further Cleaning:**  
  You may further clean the merged files (e.g., remove unused columns) before evaluation if needed.

- **Folder Structure:**  
  Keep the folder structure as shown above for scripts to work out-of-the-box.

---

## âš ï¸ Things to Care About

- Always update the ground truth file name in `concat_tables.py` if your dataset changes.
- Always update the merged file name in `evaluate_results.py` to point to the latest results.
- All evaluation results are organized by timestamp in the `evaluations/` folder for easy tracking.

---

## â“ Questions

If you have any questions or need help, please contact [Diwash Patel].

---